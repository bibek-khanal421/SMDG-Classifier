Epoch 1/20
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C7FEA20790> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: cannot import name 'soft_unicode' from 'markupsafe' (c:\Users\Anton\anaconda3\envs\ML\lib\site-packages\markupsafe\__init__.py)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001C7FEA20790> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: cannot import name 'soft_unicode' from 'markupsafe' (c:\Users\Anton\anaconda3\envs\ML\lib\site-packages\markupsafe\__init__.py)
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert














































































































215/215 [==============================] - 292s 1s/step - loss: 0.4514 - accuracy: 0.7920 - val_loss: 0.6923 - val_accuracy: 0.7411
Epoch 2/20














































































































215/215 [==============================] - 279s 1s/step - loss: 0.3564 - accuracy: 0.8405 - val_loss: 0.8282 - val_accuracy: 0.6287
Epoch 3/20












































































































215/215 [==============================] - 270s 1s/step - loss: 0.3066 - accuracy: 0.8613 - val_loss: 0.3518 - val_accuracy: 0.8498
Epoch 4/20














































































































215/215 [==============================] - 275s 1s/step - loss: 0.2915 - accuracy: 0.8734 - val_loss: 0.3436 - val_accuracy: 0.8506
Epoch 5/20













































































































215/215 [==============================] - 275s 1s/step - loss: 0.2708 - accuracy: 0.8841 - val_loss: 0.3547 - val_accuracy: 0.8596
Epoch 6/20











































































































215/215 [==============================] - 271s 1s/step - loss: 0.2516 - accuracy: 0.8897 - val_loss: 0.4853 - val_accuracy: 0.8612
Epoch 7/20















































































































215/215 [==============================] - 278s 1s/step - loss: 0.2367 - accuracy: 0.8956 - val_loss: 0.4891 - val_accuracy: 0.8304
Epoch 8/20


















































































































215/215 [==============================] - 284s 1s/step - loss: 0.2252 - accuracy: 0.9021 - val_loss: 0.4361 - val_accuracy: 0.8393
Epoch 9/20











































































































215/215 [==============================] - 268s 1s/step - loss: 0.2041 - accuracy: 0.9088 - val_loss: 0.3470 - val_accuracy: 0.8604










31/31 [==============================] - 22s 663ms/step - loss: 0.3459 - accuracy: 0.8438










31/31 [==============================] - 23s 699ms/step









31/31 [==============================] - 21s 689ms/step
Accuracy on test dataset:  0.8438133597373962
Classification report:
               precision    recall  f1-score   support
           0       0.83      0.92      0.88       589
           1       0.87      0.73      0.79       397
    accuracy                           0.84       986
   macro avg       0.85      0.83      0.83       986
weighted avg       0.85      0.84      0.84       986
Confusion matrix:
1/1 [==============================] - 1s 1s/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 34ms/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 42ms/step
Predicted label: [[1.]]
Actual label: 1
1/1 [==============================] - 0s 37ms/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 37ms/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 33ms/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 40ms/step
Predicted label: [[1.]]
Actual label: 0
1/1 [==============================] - 0s 52ms/step
Predicted label: [[0.]]
Actual label: 0
1/1 [==============================] - 0s 44ms/step
Predicted label: [[0.]]
